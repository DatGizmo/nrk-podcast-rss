import os
import logging
import configparser
import time
import yt_dlp
import datetime
import pytz
import pickle
from podgen import Podcast, Episode, Media

# The podcasts to be downloaded. Additional podcasts can be added following the
# pattern. Note that fname, should be unique, and valid as part of a filename.
podcasts = [
    {
        "name": "Dagsnytt 18",
        "url": "https://radio.nrk.no/podkast/dagsnytt_atten",
        "desc": "Dagsnytt 18",
        "fname": "dagsnytt18",
    },
    {
        "name": "Debatten",
        "url": "https://radio.nrk.no/podkast/debatten",
        "desc": "Debatten",
        "fname": "debatten",
    },
]

# Directory for rss feeds generated by the program.
OUTPUT_DIR = "/data"

# Directory for archive and pickle files that should be persistent between
# executions.
PERSISTENT_DIR = "/persistent"

if __name__ == "__main__":
    while True:
        # Load configuration.
        config = configparser.ConfigParser()
        config.read("./config/config.ini")

        # Configure logging.
        logger = logging.getLogger()
        logger.addHandler(logging.StreamHandler())
        logger.setLevel(config["logging"]["level"])

        for item in podcasts:
            url = item["url"]
            title = item["name"]
            desc = item["desc"]

            # File paths for generated files.
            archive_file = os.path.join(PERSISTENT_DIR, f"{item['fname']}.txt")
            pickle_file = os.path.join(PERSISTENT_DIR, f"{item['fname']}.pickle")
            rss_file = os.path.join(OUTPUT_DIR, f"{item['fname']}.rss")

            ydl = yt_dlp.YoutubeDL()
            info = ydl.extract_info(url, download=False, process=False)

            try:
                with open(archive_file, "r") as f:
                    archive = set(f.read().splitlines())
            except FileNotFoundError:
                logger.info("No archive file found.")
                archive = set([])

            if os.path.isfile(pickle_file):
                # https://github.com/lkiesow/python-feedgen/issues/72
                # Workaround for podgen not being able to load from existing rss
                # file.
                logger.info("Loading existing Podcast object from pickle file")
                with open(pickle_file, "rb") as f:
                    pod = pickle.load(f)
            else:
                logger.info("No existing pickle found. Create new Podcast object")
                pod = Podcast()
                pod.name = title
                pod.website = url
                pod.description = desc
                pod.explicit = False

            for e in info["entries"]:
                # The information returned has entries for both "episodes" and
                # "seasons". Only episodes have an "id" key, so we use that to
                # only process the episodes.
                if "id" in e.keys():
                    if e["url"] in archive:
                        logger.info(
                            f"Skipping episode {e['url']}, due to already being in archive."
                        )
                    else:
                        episode_info = ydl.extract_info(
                            e["url"], download=False, process=True
                        )

                        ep = Episode()
                        ep.title = episode_info["title"]
                        ep.summary = episode_info.get("summary", "")
                        ep.media = Media(episode_info["url"])
                        ep.publication_date = datetime.datetime.fromtimestamp(
                            episode_info["timestamp"],
                            tz=pytz.timezone("Europe/Oslo"),
                        )
                        pod.add_episode(ep)

                        pod.rss_file(os.path.join(rss_file), encoding="UTF-8")

                        with open(archive_file, "a") as f:
                            f.write(e["url"] + "\n")

                        with open(pickle_file, "wb") as f:
                            pickle.dump(pod, f)

        time.sleep(int(config["updates"]["frequency_sec"]))
